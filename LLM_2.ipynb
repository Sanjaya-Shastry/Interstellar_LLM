{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10635200",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/sanjayashastry/Downloads/interstellar_script.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c8b06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe1cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the text\n",
    "\n",
    "text = text.lower()\n",
    "lines = text.splitlines()\n",
    "cleaned_lines = [line.strip() for line in lines if line.strip() != '']\n",
    "cleaned_text = ' '.join(cleaned_lines)\n",
    "\n",
    "import string\n",
    "\n",
    "allowed_chars = set(string.ascii_letters + string.digits + \" \")\n",
    "cleaned_text= ''.join(char for char in cleaned_text if char in allowed_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc8772a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'interstellar written by jonathan nolan and christopher nolan transferred to pdf from interstellar  the complete screenplay with selected storyboards published november 2014 by faber  faber ltd uk for '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7deaf0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "\n",
    "tokens= cleaned_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "951cd690",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab= sorted(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e16540",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27fa686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size= len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e7f847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = np.array([word_to_idx[word] for word in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42f7eaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1462, 3253,  367, ..., 1947,  607,  857])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee563173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24489, 3284)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_ids),vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c9e5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 6\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(context_size, len(token_ids)):\n",
    "    context = token_ids[i - context_size:i]\n",
    "    target = token_ids[i]\n",
    "    X.append(context)\n",
    "    y.append(target)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20d38847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1462, 3253,  367, 1494, 1864,   89]),\n",
       " array([3253,  367, 1494, 1864,   89,  449]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0],X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aab30d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(449)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab2d5f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#embedding\n",
    "\n",
    "embedding_dim= 64\n",
    "embedding_layer = layers.Embedding(\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=embedding_dim,\n",
    "    input_length=context_size,\n",
    "    name=\"word_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d17a6312",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = tf.convert_to_tensor(X, dtype=tf.int32) \n",
    "embedded_output = embedding_layer(X_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d666441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24483, 6), dtype=int32, numpy=\n",
       "array([[1462, 3253,  367, 1494, 1864,   89],\n",
       "       [3253,  367, 1494, 1864,   89,  449],\n",
       "       [ 367, 1494, 1864,   89,  449, 1864],\n",
       "       ...,\n",
       "       [2999, 2940,  381,   89, 3132,  946],\n",
       "       [2940,  381,   89, 3132,  946, 1947],\n",
       "       [ 381,   89, 3132,  946, 1947,  607]], dtype=int32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e37573b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24483, 6, 64), dtype=float32, numpy=\n",
       "array([[[-0.04231769, -0.00695965, -0.02362796, ...,  0.00782615,\n",
       "          0.04626682,  0.016004  ],\n",
       "        [-0.04226515, -0.02959578,  0.03503232, ..., -0.02892702,\n",
       "         -0.04453003,  0.03919861],\n",
       "        [-0.04262077,  0.02134294,  0.01993401, ..., -0.02101747,\n",
       "         -0.03222983,  0.00358448],\n",
       "        [ 0.02524828,  0.0066609 , -0.00214107, ..., -0.02450227,\n",
       "         -0.01353761,  0.01561255],\n",
       "        [-0.01723098,  0.02548292,  0.04533874, ..., -0.03356725,\n",
       "         -0.04238709, -0.00065075],\n",
       "        [-0.0350266 ,  0.01233538,  0.03191798, ..., -0.03715302,\n",
       "         -0.01159427,  0.02017493]],\n",
       "\n",
       "       [[-0.04226515, -0.02959578,  0.03503232, ..., -0.02892702,\n",
       "         -0.04453003,  0.03919861],\n",
       "        [-0.04262077,  0.02134294,  0.01993401, ..., -0.02101747,\n",
       "         -0.03222983,  0.00358448],\n",
       "        [ 0.02524828,  0.0066609 , -0.00214107, ..., -0.02450227,\n",
       "         -0.01353761,  0.01561255],\n",
       "        [-0.01723098,  0.02548292,  0.04533874, ..., -0.03356725,\n",
       "         -0.04238709, -0.00065075],\n",
       "        [-0.0350266 ,  0.01233538,  0.03191798, ..., -0.03715302,\n",
       "         -0.01159427,  0.02017493],\n",
       "        [ 0.01182253, -0.03102115,  0.03033182, ..., -0.03742343,\n",
       "          0.01582788,  0.01558958]],\n",
       "\n",
       "       [[-0.04262077,  0.02134294,  0.01993401, ..., -0.02101747,\n",
       "         -0.03222983,  0.00358448],\n",
       "        [ 0.02524828,  0.0066609 , -0.00214107, ..., -0.02450227,\n",
       "         -0.01353761,  0.01561255],\n",
       "        [-0.01723098,  0.02548292,  0.04533874, ..., -0.03356725,\n",
       "         -0.04238709, -0.00065075],\n",
       "        [-0.0350266 ,  0.01233538,  0.03191798, ..., -0.03715302,\n",
       "         -0.01159427,  0.02017493],\n",
       "        [ 0.01182253, -0.03102115,  0.03033182, ..., -0.03742343,\n",
       "          0.01582788,  0.01558958],\n",
       "        [-0.01723098,  0.02548292,  0.04533874, ..., -0.03356725,\n",
       "         -0.04238709, -0.00065075]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.00962049,  0.0138683 ,  0.01038434, ..., -0.03841474,\n",
       "          0.02903188, -0.03252266],\n",
       "        [-0.0115479 , -0.04584882, -0.003738  , ..., -0.0078015 ,\n",
       "         -0.04636   ,  0.03289601],\n",
       "        [-0.03393479,  0.04096253, -0.04779161, ..., -0.02470524,\n",
       "          0.00531274,  0.00188739],\n",
       "        [-0.0350266 ,  0.01233538,  0.03191798, ..., -0.03715302,\n",
       "         -0.01159427,  0.02017493],\n",
       "        [ 0.02076164,  0.00868259,  0.02268428, ..., -0.04522455,\n",
       "          0.04037795, -0.03647597],\n",
       "        [-0.03868483, -0.02649504, -0.01540796, ..., -0.00449023,\n",
       "          0.02859691,  0.0183827 ]],\n",
       "\n",
       "       [[-0.0115479 , -0.04584882, -0.003738  , ..., -0.0078015 ,\n",
       "         -0.04636   ,  0.03289601],\n",
       "        [-0.03393479,  0.04096253, -0.04779161, ..., -0.02470524,\n",
       "          0.00531274,  0.00188739],\n",
       "        [-0.0350266 ,  0.01233538,  0.03191798, ..., -0.03715302,\n",
       "         -0.01159427,  0.02017493],\n",
       "        [ 0.02076164,  0.00868259,  0.02268428, ..., -0.04522455,\n",
       "          0.04037795, -0.03647597],\n",
       "        [-0.03868483, -0.02649504, -0.01540796, ..., -0.00449023,\n",
       "          0.02859691,  0.0183827 ],\n",
       "        [-0.0201592 ,  0.0084003 ,  0.0444147 , ..., -0.01631552,\n",
       "          0.03447973,  0.02899593]],\n",
       "\n",
       "       [[-0.03393479,  0.04096253, -0.04779161, ..., -0.02470524,\n",
       "          0.00531274,  0.00188739],\n",
       "        [-0.0350266 ,  0.01233538,  0.03191798, ..., -0.03715302,\n",
       "         -0.01159427,  0.02017493],\n",
       "        [ 0.02076164,  0.00868259,  0.02268428, ..., -0.04522455,\n",
       "          0.04037795, -0.03647597],\n",
       "        [-0.03868483, -0.02649504, -0.01540796, ..., -0.00449023,\n",
       "          0.02859691,  0.0183827 ],\n",
       "        [-0.0201592 ,  0.0084003 ,  0.0444147 , ..., -0.01631552,\n",
       "          0.03447973,  0.02899593],\n",
       "        [-0.00952635,  0.00352184,  0.02084519, ..., -0.03069527,\n",
       "         -0.00397358,  0.04553323]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93935b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Variable path=word_embedding/embeddings, shape=(3284, 64), dtype=float32, value=[[-0.04035167  0.00994016  0.04380003 ... -0.0307601  -0.04100013\n",
       "  -0.0189991 ]\n",
       " [-0.00613187 -0.02368096 -0.0248044  ...  0.01691686  0.02221227\n",
       "  -0.02468401]\n",
       " [ 0.04954371 -0.01578617 -0.03552318 ... -0.00460106 -0.01872165\n",
       "   0.04332887]\n",
       " ...\n",
       " [ 0.01559821 -0.01572269  0.00327324 ...  0.02265764  0.02303386\n",
       "   0.00509912]\n",
       " [ 0.00610654  0.01632574 -0.01482235 ... -0.01334463 -0.00787904\n",
       "   0.0137468 ]\n",
       " [ 0.02193556 -0.02646337 -0.00402904 ... -0.01972905 -0.01474252\n",
       "   0.04712917]]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "606ea27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape after adding positional encoding: (24483, 6, 64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_positional_encoding(context_size, embedding_dim):\n",
    "    pos_enc = np.zeros((context_size, embedding_dim))\n",
    "    for pos in range(context_size):\n",
    "        for i in range(embedding_dim):\n",
    "            angle = pos / np.power(10000, (2 * (i // 2)) / embedding_dim)\n",
    "            if i % 2 == 0:\n",
    "                pos_enc[pos, i] = np.sin(angle)\n",
    "            else:\n",
    "                pos_enc[pos, i] = np.cos(angle)\n",
    "    return tf.convert_to_tensor(pos_enc, dtype=tf.float32)  # shape: (context_size, embedding_dim)\n",
    "\n",
    "# Generate the positional encoding matrix\n",
    "positional_encoding = get_positional_encoding(context_size, embedding_dim)\n",
    "\n",
    "# embedded_output shape: (batch_size, context_size, embedding_dim)\n",
    "# positional_encoding shape: (context_size, embedding_dim)\n",
    "\n",
    "# Add positional encoding to each sample in the batch\n",
    "embedded_with_pos = embedded_output + positional_encoding  # broadcasting will work automatically\n",
    "\n",
    "print(\"Final shape after adding positional encoding:\", embedded_with_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17c6da31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24483, 6, 64), dtype=float32, numpy=\n",
       "array([[[-0.04231769,  0.9930403 , -0.02362796, ...,  1.0078261 ,\n",
       "          0.04626682,  1.016004  ],\n",
       "        [ 0.7992058 ,  0.5107065 ,  0.7165937 , ...,  0.971073  ,\n",
       "         -0.04439668,  1.0391986 ],\n",
       "        [ 0.8666766 , -0.3948039 ,  1.017414  , ...,  0.97898245,\n",
       "         -0.03196312,  1.0035844 ],\n",
       "        [ 0.16636828, -0.9833316 ,  0.77613145, ...,  0.9754976 ,\n",
       "         -0.01313755,  1.0156125 ],\n",
       "        [-0.7740335 , -0.6281607 ,  0.18687765, ...,  0.9664325 ,\n",
       "         -0.04185368,  0.9993491 ],\n",
       "        [-0.9939509 ,  0.2959976 , -0.5392092 , ...,  0.9628466 ,\n",
       "         -0.01092751,  1.0201747 ]],\n",
       "\n",
       "       [[-0.04226515,  0.9704042 ,  0.03503232, ...,  0.971073  ,\n",
       "         -0.04453003,  1.0391986 ],\n",
       "        [ 0.7988502 ,  0.5616452 ,  0.70149535, ...,  0.9789825 ,\n",
       "         -0.03209648,  1.0035845 ],\n",
       "        [ 0.9345457 , -0.40948594,  0.9953389 , ...,  0.97549766,\n",
       "         -0.0132709 ,  1.0156125 ],\n",
       "        [ 0.12388903, -0.9645096 ,  0.82361126, ...,  0.96643263,\n",
       "         -0.04198704,  0.9993492 ],\n",
       "        [-0.7918291 , -0.64130825,  0.17345689, ...,  0.96284676,\n",
       "         -0.01106086,  1.0201749 ],\n",
       "        [-0.9471018 ,  0.25264105, -0.5407953 , ...,  0.96257615,\n",
       "          0.01649464,  1.0155894 ]],\n",
       "\n",
       "       [[-0.04262077,  1.021343  ,  0.01993401, ...,  0.9789825 ,\n",
       "         -0.03222983,  1.0035845 ],\n",
       "        [ 0.86671925,  0.54696316,  0.6794203 , ...,  0.9754977 ,\n",
       "         -0.01340426,  1.0156126 ],\n",
       "        [ 0.8920664 , -0.39066392,  1.0428187 , ...,  0.9664327 ,\n",
       "         -0.04212039,  0.9993492 ],\n",
       "        [ 0.10609341, -0.97765714,  0.8101905 , ...,  0.9628469 ,\n",
       "         -0.01119422,  1.0201749 ],\n",
       "        [-0.74498   , -0.6846648 ,  0.17187074, ...,  0.9625763 ,\n",
       "          0.01636129,  1.0155895 ],\n",
       "        [-0.9761553 ,  0.30914512, -0.5257884 , ...,  0.96643233,\n",
       "         -0.04172033,  0.999349  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.00962049,  1.0138683 ,  0.01038434, ...,  0.9615853 ,\n",
       "          0.02903188,  0.9674773 ],\n",
       "        [ 0.82992303,  0.49445346,  0.67782336, ...,  0.9921985 ,\n",
       "         -0.04622665,  1.032896  ],\n",
       "        [ 0.87536263, -0.37518433,  0.9496884 , ...,  0.9752947 ,\n",
       "          0.00557945,  1.0018873 ],\n",
       "        [ 0.10609341, -0.97765714,  0.8101905 , ...,  0.9628469 ,\n",
       "         -0.01119422,  1.0201749 ],\n",
       "        [-0.7360409 , -0.644961  ,  0.1642232 , ...,  0.9547752 ,\n",
       "          0.04091136,  0.9635239 ],\n",
       "        [-0.99760914,  0.25716716, -0.58653516, ...,  0.9955093 ,\n",
       "          0.02926367,  1.0183824 ]],\n",
       "\n",
       "       [[-0.0115479 ,  0.95415115, -0.003738  , ...,  0.9921985 ,\n",
       "         -0.04636   ,  1.032896  ],\n",
       "        [ 0.8075362 ,  0.5812648 ,  0.63376975, ...,  0.97529477,\n",
       "          0.00544609,  1.0018874 ],\n",
       "        [ 0.8742708 , -0.40381145,  1.029398  , ...,  0.96284693,\n",
       "         -0.01132757,  1.0201749 ],\n",
       "        [ 0.16188164, -0.9813099 ,  0.8009568 , ...,  0.95477533,\n",
       "          0.040778  ,  0.963524  ],\n",
       "        [-0.79548734, -0.68013865,  0.12613097, ...,  0.9955095 ,\n",
       "          0.02913032,  1.0183825 ],\n",
       "        [-0.9790835 ,  0.2920625 , -0.5267125 , ...,  0.98368406,\n",
       "          0.03514649,  1.0289958 ]],\n",
       "\n",
       "       [[-0.03393479,  1.0409626 , -0.04779161, ...,  0.97529477,\n",
       "          0.00531274,  1.0018874 ],\n",
       "        [ 0.80644435,  0.55263764,  0.71347934, ...,  0.962847  ,\n",
       "         -0.01146092,  1.020175  ],\n",
       "        [ 0.930059  , -0.40746427,  1.0201643 , ...,  0.9547754 ,\n",
       "          0.04064465,  0.963524  ],\n",
       "        [ 0.10243517, -1.0164876 ,  0.76286453, ...,  0.9955096 ,\n",
       "          0.02899697,  1.0183827 ],\n",
       "        [-0.7769617 , -0.6452433 ,  0.18595362, ...,  0.98368424,\n",
       "          0.03501314,  1.0289959 ],\n",
       "        [-0.96845067,  0.28718403, -0.550282  , ...,  0.9693043 ,\n",
       "         -0.00330682,  1.045533  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_with_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1aae9d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_with_pos.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f823ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer block\n",
    "\n",
    "head_dim = embedding_dim  # For single head, often D = d_k = d_v\n",
    "\n",
    "# Initialize trainable weights for Q, K, V\n",
    "W_q = tf.Variable(tf.random.normal([embedding_dim, head_dim]), name='W_q')\n",
    "W_k = tf.Variable(tf.random.normal([embedding_dim, head_dim]), name='W_k')\n",
    "W_v = tf.Variable(tf.random.normal([embedding_dim, head_dim]), name='W_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab588dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attention(embedded_with_pos):\n",
    "    # Shape: (batch, T, D)\n",
    "    Q = tf.einsum('bij,jk->bik', embedded_with_pos, W_q)  \n",
    "    K = tf.einsum('bij,jk->bik', embedded_with_pos, W_k)\n",
    "    V = tf.einsum('bij,jk->bik', embedded_with_pos, W_v)\n",
    "    \n",
    "    return Q, K, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3933e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(Q, K, V):\n",
    "    d_k = tf.cast(tf.shape(K)[-1], tf.float32)\n",
    "\n",
    "    # Attention scores: Q @ Kᵗ\n",
    "    scores = tf.einsum('bij,bkj->bik', Q, K)  \n",
    "    scores /= tf.math.sqrt(d_k)\n",
    "\n",
    "    # Softmax across keys\n",
    "    attention_weights = tf.nn.softmax(scores, axis=-1)  \n",
    "\n",
    "    # Weighted sum of values\n",
    "    output = tf.einsum('bij,bjk->bik', attention_weights, V) \n",
    "    \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cedd2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, K, V = compute_attention(embedded_with_pos)\n",
    "attended_output, attn_weights = scaled_dot_product_attention(Q, K, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "366eaf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_output = attended_output[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8745be",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = layers.Dense(vocab_size)\n",
    "logits = output_layer(last_token_output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c88e1bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdfb3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b54ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Loss: 3.5952\n",
      "Epoch 2/30 - Loss: 3.5134\n",
      "Epoch 3/30 - Loss: 3.4514\n",
      "Epoch 4/30 - Loss: 3.4036\n",
      "Epoch 5/30 - Loss: 3.3661\n",
      "Epoch 6/30 - Loss: 3.3350\n",
      "Epoch 7/30 - Loss: 3.3112\n",
      "Epoch 8/30 - Loss: 3.2893\n",
      "Epoch 9/30 - Loss: 3.2721\n",
      "Epoch 10/30 - Loss: 3.2576\n",
      "Epoch 11/30 - Loss: 3.2455\n",
      "Epoch 12/30 - Loss: 3.2341\n",
      "Epoch 13/30 - Loss: 3.2240\n",
      "Epoch 14/30 - Loss: 3.2159\n",
      "Epoch 15/30 - Loss: 3.2070\n",
      "Epoch 16/30 - Loss: 3.1990\n",
      "Epoch 17/30 - Loss: 3.1915\n",
      "Epoch 18/30 - Loss: 3.1852\n",
      "Epoch 19/30 - Loss: 3.1796\n",
      "Epoch 20/30 - Loss: 3.1731\n",
      "Epoch 21/30 - Loss: 3.1695\n",
      "Epoch 22/30 - Loss: 3.1619\n",
      "Epoch 23/30 - Loss: 3.1560\n",
      "Epoch 24/30 - Loss: 3.1528\n",
      "Epoch 25/30 - Loss: 3.1472\n",
      "Epoch 26/30 - Loss: 3.1433\n",
      "Epoch 27/30 - Loss: 3.1387\n",
      "Epoch 28/30 - Loss: 3.1358\n",
      "Epoch 29/30 - Loss: 3.1325\n",
      "Epoch 30/30 - Loss: 3.1322\n"
     ]
    }
   ],
   "source": [
    "# Converting y to tensor\n",
    "y_tensor = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "\n",
    "# Training hyperparameters\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    num_batches = int(np.ceil(len(X) / batch_size))\n",
    "    \n",
    "    for i in range(0, len(X), batch_size):\n",
    "        X_batch = X[i:i+batch_size]\n",
    "        y_batch = y_tensor[i:i+batch_size]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            X_tensor = tf.convert_to_tensor(X_batch, dtype=tf.int32)\n",
    "            embedded_output = embedding_layer(X_tensor)\n",
    "            embedded_with_pos = embedded_output + positional_encoding\n",
    "\n",
    "            Q, K, V = compute_attention(embedded_with_pos)\n",
    "            attended_output, _ = scaled_dot_product_attention(Q, K, V)\n",
    "            last_token_output = attended_output[:, -1, :]\n",
    "            logits = output_layer(last_token_output)\n",
    "\n",
    "            loss = loss_fn(y_batch, logits)\n",
    "\n",
    "        gradients = tape.gradient(loss, [embedding_layer.trainable_variables[0], \n",
    "                                         W_q, W_k, W_v, \n",
    "                                         output_layer.trainable_variables[0], \n",
    "                                         output_layer.trainable_variables[1]])\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradients, \n",
    "                                      [embedding_layer.trainable_variables[0], \n",
    "                                       W_q, W_k, W_v, \n",
    "                                       output_layer.trainable_variables[0], \n",
    "                                       output_layer.trainable_variables[1]]))\n",
    "\n",
    "        epoch_loss += loss.numpy()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss/num_batches:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "181f718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_logits(logits, temperature=0.7):\n",
    "    logits = logits / temperature\n",
    "    probs = tf.nn.softmax(logits).numpy().flatten()\n",
    "    return np.random.choice(len(probs), p=probs)\n",
    "\n",
    "def generate_text(seed_text, num_words=20, temperature=0.7):\n",
    "    generated = seed_text.lower().split()\n",
    "    for _ in range(num_words):\n",
    "        context = generated[-context_size:]\n",
    "        if len(context) < context_size:\n",
    "            context = [''] * (context_size - len(context)) + context\n",
    "        context_ids = [word_to_idx.get(w, 0) for w in context]\n",
    "        X_input = tf.convert_to_tensor([context_ids], dtype=tf.int32)\n",
    "\n",
    "        embedded_output = embedding_layer(X_input)\n",
    "        embedded_with_pos = embedded_output + positional_encoding\n",
    "\n",
    "        Q, K, V = compute_attention(embedded_with_pos)\n",
    "        attended_output, _ = scaled_dot_product_attention(Q, K, V)\n",
    "        last_token_output = attended_output[:, -1, :]\n",
    "        logits = output_layer(last_token_output)\n",
    "\n",
    "        next_id = sample_from_logits(logits, temperature)\n",
    "        next_word = idx_to_word[next_id]\n",
    "        generated.append(next_word)\n",
    "\n",
    "    return ' '.join(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22ee0575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love is there even worked out int murphs bedroom twilight murph ten\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\" Love is \", num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a4c245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
